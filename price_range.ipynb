{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRBjG71s_Cta"
      },
      "source": [
        "\n",
        "***\n",
        "# Classification - ML Section\n",
        "\n",
        "***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHyPnM3G_Ctb"
      },
      "source": [
        "## Importing Packages "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-y3RQvtkOjqp",
        "outputId": "2020086b-9897-4765-8701-8959647b6477"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 47 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 36.7 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=84e5eff64b79760488cca6143bfe682ab812488887349c02fa468f5110ce5dae\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/dc/11/ec201cd671da62fa9c5cc77078235e40722170ceba231d7598\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "y7dQc4oDc0fz"
      },
      "outputs": [],
      "source": [
        "#import libary\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import types\n",
        "from pyspark.sql.functions import col, isnan, when, count, explode, array, lit\n",
        "\n",
        "\n",
        "from pyspark.ml.feature import Imputer, VectorAssembler, StringIndexer\n",
        "from pyspark.ml.regression import RandomForestRegressor, DecisionTreeRegressor, GBTRegressor, LinearRegression\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pandadf = pd.read_csv('cleaning_data 2.csv')"
      ],
      "metadata": {
        "id": "imolJzaCJnno"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y228EzriOTcl"
      },
      "source": [
        "## connect to  spark "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n"
      ],
      "metadata": {
        "id": "f2Y-Wp34QG2H"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aMmoIDWkOTcm"
      },
      "outputs": [],
      "source": [
        "spark = pyspark.sql.SparkSession.builder.config(\"spark.executor.memory\", \"16g\").config(\"spark.driver.memory\", \"16g\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n"
      ],
      "metadata": {
        "id": "aVBeM9g7RF53"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame(pandadf)\n"
      ],
      "metadata": {
        "id": "LZFmIzUUNex1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbFzxDVL_Ctd"
      },
      "source": [
        "## Loading Dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeIq9PWLaGof",
        "outputId": "f3998e86-a1d7-4342-9cf9-0c04ed584448"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[restaurant_name: string, country: string, region: string, city: string, latitude: double, longitude: double, claimed: string, popularity_detailed: string, popularity_generic: string, cuisines: string, vegetarian_friendly: bigint, vegan_options: bigint, gluten_free: bigint, open_days_per_week: bigint, open_hours_per_week: double, working_shifts_per_week: bigint, avg_rating: double, total_reviews_count: bigint, default_language: string, reviews_count_in_default_language: bigint, excellent: double, very_good: double, average: double, poor: double, terrible: double, food: double, service: double, value: double, atmosphere: double, price_range: string]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#SHOW DATA\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X13TVCUlFaT4",
        "outputId": "b4c4ab79-24be-40e5-cf9c-37d8f8fa3b72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the dataset:  (749544, 30)\n"
          ]
        }
      ],
      "source": [
        "print('Shape of the dataset: ',(df.count(), len(df.columns)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6I0PCCySOTcu"
      },
      "source": [
        "## drop non values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WWa_FzTuOTcu"
      },
      "outputs": [],
      "source": [
        "#drop all null valures\n",
        "data=df.dropna()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GP0G2Q-i_Cti"
      },
      "source": [
        "***\n",
        "# ML Classification Section \n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKG4whcF_Cti"
      },
      "source": [
        "## Feature Engineering and Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "yLzES1neOTdM",
        "outputId": "9837ac39-b4c1-4a8a-d952-e12b7d398073",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- restaurant_name: string (nullable = true)\n",
            " |-- country: string (nullable = true)\n",
            " |-- region: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- latitude: double (nullable = true)\n",
            " |-- longitude: double (nullable = true)\n",
            " |-- claimed: string (nullable = true)\n",
            " |-- popularity_detailed: string (nullable = true)\n",
            " |-- popularity_generic: string (nullable = true)\n",
            " |-- cuisines: string (nullable = true)\n",
            " |-- vegetarian_friendly: long (nullable = true)\n",
            " |-- vegan_options: long (nullable = true)\n",
            " |-- gluten_free: long (nullable = true)\n",
            " |-- open_days_per_week: long (nullable = true)\n",
            " |-- open_hours_per_week: double (nullable = true)\n",
            " |-- working_shifts_per_week: long (nullable = true)\n",
            " |-- avg_rating: double (nullable = true)\n",
            " |-- total_reviews_count: long (nullable = true)\n",
            " |-- default_language: string (nullable = true)\n",
            " |-- reviews_count_in_default_language: long (nullable = true)\n",
            " |-- excellent: double (nullable = true)\n",
            " |-- very_good: double (nullable = true)\n",
            " |-- average: double (nullable = true)\n",
            " |-- poor: double (nullable = true)\n",
            " |-- terrible: double (nullable = true)\n",
            " |-- food: double (nullable = true)\n",
            " |-- service: double (nullable = true)\n",
            " |-- value: double (nullable = true)\n",
            " |-- atmosphere: double (nullable = true)\n",
            " |-- price_range: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data.printSchema()#show "
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CTt0b2-Oa6dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "M9kdQlj2_Cti"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import FloatType \n",
        "\n",
        "\n",
        "spark = data.replace( \"mid\" , '0', subset=[\"price_range\"]) #replace mid range to 0\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "GuUaBz1jTyWk"
      },
      "outputs": [],
      "source": [
        "spark = spark.replace('cheap' , '1', subset=[\"price_range\"]) #replace  cheap range 1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import IntegerType \n"
      ],
      "metadata": {
        "id": "WOQiv-kVt-av"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = spark.withColumn(\"vegetarian_friendly\", spark[\"vegetarian_friendly\"].cast(IntegerType())) #convert vegetarian_friendly type to  int type\n"
      ],
      "metadata": {
        "id": "y1qVG3jnt4EK"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = spark.withColumn(\"avg_rating\", spark[\"avg_rating\"].cast(FloatType())) #convert avg_rating type to  int type\n"
      ],
      "metadata": {
        "id": "F7rz59Uxw2aZ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = spark.withColumn(\"vegan_options\", spark[\"vegan_options\"].cast(IntegerType())) #convert vegan_options type to  int type\n"
      ],
      "metadata": {
        "id": "qnnLs5YPt4Ri"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = spark.withColumn(\"reviews_count_in_default_language\", spark[\"reviews_count_in_default_language\"].cast(IntegerType())) #convert reviews_count_in_default_language type to  int type\n"
      ],
      "metadata": {
        "id": "1zy9UhXtuclM"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "spark = spark.withColumn(\"price_range\", spark[\"price_range\"].cast(IntegerType())) #convert price_range type to  int type\n"
      ],
      "metadata": {
        "id": "LPyi8dzkOu2I"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.groupBy(\"price_range\").count().show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qm4u7wyAwFG9",
        "outputId": "49d0d98f-43f1-4787-f366-5e67fe06e709"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------+\n",
            "|price_range| count|\n",
            "+-----------+------+\n",
            "|          0|521534|\n",
            "|          1|227990|\n",
            "+-----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "major_df = spark.filter(col(\"price_range\") == 0)\n",
        "minor_df = spark.filter(col(\"price_range\") == 1)\n",
        "\n",
        "\n",
        "\n",
        "#we will calculate the ratio to determine the difference between the number of price_range 0 and price_range 1 transactions.\n",
        "ratio = int(major_df.count()/minor_df.count())\n",
        "print(\"ratio: {}\".format(ratio))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcdVfweGuhAA",
        "outputId": "e5506858-2c53-4d93-aee8-80a524f009d8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ratio: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df = spark "
      ],
      "metadata": {
        "id": "KaFqfri9OFGL"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHlQBYEFOTdN",
        "outputId": "646c3299-9a15-4e29-d0af-ad8ff7da900e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- restaurant_name: string (nullable = true)\n",
            " |-- country: string (nullable = true)\n",
            " |-- region: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- latitude: double (nullable = true)\n",
            " |-- longitude: double (nullable = true)\n",
            " |-- claimed: string (nullable = true)\n",
            " |-- popularity_detailed: string (nullable = true)\n",
            " |-- popularity_generic: string (nullable = true)\n",
            " |-- cuisines: string (nullable = true)\n",
            " |-- vegetarian_friendly: long (nullable = true)\n",
            " |-- vegan_options: long (nullable = true)\n",
            " |-- gluten_free: long (nullable = true)\n",
            " |-- open_days_per_week: long (nullable = true)\n",
            " |-- open_hours_per_week: double (nullable = true)\n",
            " |-- working_shifts_per_week: long (nullable = true)\n",
            " |-- avg_rating: double (nullable = true)\n",
            " |-- total_reviews_count: long (nullable = true)\n",
            " |-- default_language: string (nullable = true)\n",
            " |-- reviews_count_in_default_language: long (nullable = true)\n",
            " |-- excellent: double (nullable = true)\n",
            " |-- very_good: double (nullable = true)\n",
            " |-- average: double (nullable = true)\n",
            " |-- poor: double (nullable = true)\n",
            " |-- terrible: double (nullable = true)\n",
            " |-- food: double (nullable = true)\n",
            " |-- service: double (nullable = true)\n",
            " |-- value: double (nullable = true)\n",
            " |-- atmosphere: double (nullable = true)\n",
            " |-- price_range: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "combined_df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "a98akuS8Rs7p"
      },
      "outputs": [],
      "source": [
        "#This step will label encode all the categorical columns and store them in different columns with the same name + '_idx', \n",
        "#so category will become category_idx \n",
        "cat_cols = ['cuisines','claimed'] #cuisines and price_range\n",
        "\n",
        "#StringIndexer() is equivalent to LabelEncoder()\n",
        "for c in cat_cols: \n",
        "    indexer = StringIndexer(inputCol=c, outputCol=c+'_idx') #we pass the columns from the list as input one by one\n",
        "    combined_df = indexer.fit(combined_df).transform(combined_df) #here we fit and transform the data altogether\n",
        "    \n",
        "final_df2 = combined_df.drop(*cat_cols) #we will drop all the categorical columns we defined earlier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ab_SFd3Lse5F"
      },
      "source": [
        "## Split Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "p8cL4m6vRs7q"
      },
      "outputs": [],
      "source": [
        "#drop unneed columns\n",
        "\n",
        "final_df=final_df2.drop('average','reviews_count_in_default_language','atmosphere','default_language','working_shifts_per_week','open_hours_per_week','open_days_per_week','popularity_generic','popularity_detailed','longitude','latitude','region','city','country','restaurant_name')\n",
        "\n",
        "cols = final_df.columns #extract the column names from the dataframe\n",
        "cols.remove('price_range') #remove price_range -> we need this to be our label\n",
        "\n",
        "#vector assembler will take all the columns and convert them into one column called features\n",
        "assembler = VectorAssembler(inputCols=cols, outputCol='features')\n",
        "\n",
        "#the .transform will apply the changes here\n",
        "final_df = assembler.transform(final_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3om2mKmdOTdO",
        "outputId": "708d993a-b343-4c47-a9ed-394023a9a1ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[vegetarian_friendly: bigint, vegan_options: bigint, gluten_free: bigint, avg_rating: double, total_reviews_count: bigint, excellent: double, very_good: double, poor: double, terrible: double, food: double, service: double, value: double, price_range: int, cuisines_idx: double, claimed_idx: double, features: vector]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "#we can now see that features column will appear within the dataframe\n",
        "final_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEXpo5yfOTdO"
      },
      "source": [
        "\n",
        "Lets Split\n",
        "\n",
        "80% in training set and 20% is testing set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "UAAWTr8qOTdP"
      },
      "outputs": [],
      "source": [
        "# We will now create a new dataframe only consisting of the features column and the label column (actually stars column but renamed)\n",
        "df_data = final_df.select(col('features'), col('price_range').alias('label'))\n",
        "\n",
        "#simple data splitting\n",
        "df_train, df_test = df_data.randomSplit([0.8, 0.2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTwkfOrWswkW"
      },
      "source": [
        "## Train Models\n",
        "\n",
        "####  Note: minimum 3 models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "QimDWBJhOTdP"
      },
      "outputs": [],
      "source": [
        "# Import some classifiers and multiclass evaluator\n",
        "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier, LogisticRegression, GBTClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFK296zBug7u"
      },
      "source": [
        "### 1st Classification Model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "2z4OBK9SOTdQ"
      },
      "outputs": [],
      "source": [
        "# Decision Tree\n",
        "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\" ,maxBins=800000)\n",
        "model_dt = dt.fit(df_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvFI9DEtuXvw"
      },
      "source": [
        "### 2nd Classification Model  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "GAoyDH5-u1PZ"
      },
      "outputs": [],
      "source": [
        "# Random Forest\n",
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=8,maxDepth=5 ,maxBins=800000)\n",
        "model_rf = rf.fit(df_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ke8DFgiHu_WK"
      },
      "source": [
        "### 3rd Classification Model  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "cicu5WyGvWGy"
      },
      "outputs": [],
      "source": [
        "# Logistic Regression\n",
        "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8, labelCol=\"label\", featuresCol=\"features\")\n",
        "model_lr = lr.fit(df_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4 Classification Model  "
      ],
      "metadata": {
        "id": "k08wjqJHRjkj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "KYSMcpLeRs7t"
      },
      "outputs": [],
      "source": [
        "#NaiveBayes\n",
        "from pyspark.ml.classification import NaiveBayes\n",
        "nb = NaiveBayes(smoothing=1.0, \n",
        "                modelType=\"gaussian\", \n",
        "                featuresCol='features', labelCol='label')\n",
        "model_niv = nb.fit(df_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdLl8k9_wG6v"
      },
      "source": [
        "## Model Evaluation\n",
        "\n",
        "#### Note: This should include confusion matrix and classification report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUP0fJJdvmQj"
      },
      "source": [
        "### 1st Model  Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "ITE4LHiQvuIh"
      },
      "outputs": [],
      "source": [
        "#  pyspark has .transform\n",
        "pred_dt = model_dt.transform(df_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WewFtASjFaUk"
      },
      "source": [
        "## report  and matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj_ecisd_Ctk",
        "outputId": "d904cac4-1d59-43ff-b9c6-da913b3afba6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.99      0.82    104211\n",
            "           1       0.67      0.07      0.12     45543\n",
            "\n",
            "    accuracy                           0.71    149754\n",
            "   macro avg       0.69      0.53      0.47    149754\n",
            "weighted avg       0.70      0.71      0.61    149754\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import sklearn \n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "\n",
        "y_true = pred_dt.select(['label']).collect()\n",
        "y_pred = pred_dt.select(['prediction']).collect()\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AjaooPAkHgw",
        "outputId": "03178a98-5980-47a5-9c17-b3822b0202a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[102701   1510]\n",
            " [ 42494   3049]]\n"
          ]
        }
      ],
      "source": [
        "#matrix\n",
        "from sklearn import metrics\n",
        "matrix=metrics.confusion_matrix(y_true,y_pred)\n",
        "print(matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dadYirzrzGip"
      },
      "source": [
        "### 2nd Model  Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "W_xtasIr_Ctl"
      },
      "outputs": [],
      "source": [
        "#  pyspark has .transform\n",
        "pred_rf = model_rf.transform(df_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnwakwvlFaUl"
      },
      "source": [
        "## report  and matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZf3SMe2_Ctl",
        "outputId": "15fd4377-5af9-4283-ef2c-3d2115a4bf92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      1.00      0.82    104211\n",
            "           1       0.56      0.00      0.00     45543\n",
            "\n",
            "    accuracy                           0.70    149754\n",
            "   macro avg       0.63      0.50      0.41    149754\n",
            "weighted avg       0.65      0.70      0.57    149754\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "y_true3 = pred_rf.select(['label']).collect()\n",
        "y_pred3 = pred_rf.select(['prediction']).collect()\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(y_true3, y_pred3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ou5ZxNR1kOwQ",
        "outputId": "68ce626d-f802-44af-fc15-01abd9b4ab49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[104171     40]\n",
            " [ 45492     51]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn import metrics\n",
        "matrix=metrics.confusion_matrix(y_true3,y_pred3)\n",
        "print(matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhqUCJrNznO6"
      },
      "source": [
        "### 3rd Model  Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "nn0OzB2G_Ctl"
      },
      "outputs": [],
      "source": [
        "#  pyspark has .transform\n",
        "pred_lr = model_lr.transform(df_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JTQkkR-FaUp"
      },
      "source": [
        "## report  and matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-fZns6Hic28",
        "outputId": "005ade42-742c-4059-8676-2ab69c7d44a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      1.00      0.82    104211\n",
            "           1       0.00      0.00      0.00     45543\n",
            "\n",
            "    accuracy                           0.70    149754\n",
            "   macro avg       0.35      0.50      0.41    149754\n",
            "weighted avg       0.48      0.70      0.57    149754\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_true4 = pred_lr.select(['label']).collect()\n",
        "y_pred4 = pred_lr.select(['prediction']).collect()\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(y_true4, y_pred4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuZcXT_yj6ib",
        "outputId": "3ba281c4-b91d-47d5-a0a6-cc306d5f6270"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[104211      0]\n",
            " [ 45543      0]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn import metrics\n",
        "matrix=metrics.confusion_matrix(y_true4,y_pred4)\n",
        "print(matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9xRPPwlOTdo"
      },
      "source": [
        "### 4th Model  Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "K1N_NxawRs7v"
      },
      "outputs": [],
      "source": [
        "pred_nb = model_niv.transform(df_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U87LdQfVFaUv"
      },
      "source": [
        "## report  and matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThDvggnDikx_",
        "outputId": "7bd0147f-1192-42d9-b90d-afb5e0ab8374"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.20      0.32    104211\n",
            "           1       0.33      0.92      0.49     45543\n",
            "\n",
            "    accuracy                           0.42    149754\n",
            "   macro avg       0.60      0.56      0.41    149754\n",
            "weighted avg       0.70      0.42      0.37    149754\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_true6 = pred_nb.select(['label']).collect()\n",
        "y_pred6 = pred_nb.select(['prediction']).collect()\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(y_true6, y_pred6))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ge1ZeMFgjvZd",
        "outputId": "2700a4eb-b303-40ae-ca2d-436d001c29f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[20687 83524]\n",
            " [ 3491 42052]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn import metrics\n",
        "matrix=metrics.confusion_matrix(y_true6,y_pred6)\n",
        "print(matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3Qt31q9OTdp"
      },
      "source": [
        "## Show ML Evaluation as Dataframe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "O0qIeaoFOTdp"
      },
      "outputs": [],
      "source": [
        "# Accuracy Metric\n",
        "evaluator_A = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "\n",
        "# F1 Metric\n",
        "evaluator_F = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "\n",
        "# Weighted Precision\n",
        "evaluator_P = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
        "\n",
        "# Weighted Recall\n",
        "evaluator_R = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
        "\n",
        "# Our models\n",
        "models = [pred_dt, pred_rf, pred_lr,pred_nb]\n",
        "\n",
        "# Empty lists that will store the scores for each metric for each model.\n",
        "accuracy = []\n",
        "F1 = []\n",
        "precision = []\n",
        "recall = []\n",
        "\n",
        "# Simple loop to populate the empty lists with scores of models for each metric.\n",
        "for model in models:\n",
        "    accuracy.append(evaluator_A.evaluate(model))\n",
        "    F1.append(evaluator_F.evaluate(model))\n",
        "    precision.append(evaluator_P.evaluate(model))\n",
        "    recall.append(evaluator_R.evaluate(model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "lu-KfupAOTdq"
      },
      "outputs": [],
      "source": [
        "# We will convert all lists created above into a dataframe for easy viewing.\n",
        "df_ev = pd.DataFrame(list(zip(accuracy, F1, precision, recall)), \n",
        "                     columns = ['Accuracy', 'F1-Score', 'Weighted Precision', 'Weighted Recall'],\n",
        "                     index = ['Decision Tree', 'Random Forest', 'Logistic Regression','nive'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "PFmrj7FnOTdq",
        "outputId": "ec594913-b72c-4585-8ffd-06d9adb66c41"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     Accuracy  F1-Score  Weighted Precision  Weighted Recall\n",
              "Decision Tree        0.706158  0.610118            0.695609         0.706158\n",
              "Random Forest        0.695955  0.571756            0.654799         0.695955\n",
              "Logistic Regression  0.695881  0.571090            0.484251         0.695881\n",
              "nive                 0.418947  0.373724            0.697246         0.418947"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2469ad42-cad8-4e4b-92bc-4372d526aa1f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1-Score</th>\n",
              "      <th>Weighted Precision</th>\n",
              "      <th>Weighted Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Decision Tree</th>\n",
              "      <td>0.706158</td>\n",
              "      <td>0.610118</td>\n",
              "      <td>0.695609</td>\n",
              "      <td>0.706158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random Forest</th>\n",
              "      <td>0.695955</td>\n",
              "      <td>0.571756</td>\n",
              "      <td>0.654799</td>\n",
              "      <td>0.695955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Logistic Regression</th>\n",
              "      <td>0.695881</td>\n",
              "      <td>0.571090</td>\n",
              "      <td>0.484251</td>\n",
              "      <td>0.695881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nive</th>\n",
              "      <td>0.418947</td>\n",
              "      <td>0.373724</td>\n",
              "      <td>0.697246</td>\n",
              "      <td>0.418947</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2469ad42-cad8-4e4b-92bc-4372d526aa1f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2469ad42-cad8-4e4b-92bc-4372d526aa1f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2469ad42-cad8-4e4b-92bc-4372d526aa1f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "df_ev"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceobXQ5CdiU1"
      },
      "source": [
        "the best model is Decision Tree with 0.70 Accuracy , and the worest model is nive\t with 0.41 \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CO53Znc6d-4g"
      },
      "source": [
        "### select model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47wixViTcUOe"
      },
      "source": [
        "Decision Tree is the best model with accurcy 0.70 and \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEUrdHRYpLCA"
      },
      "source": [
        "## Model Optimization - Hyperparameter Tuning "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "JsZzq1bi_Ctm"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, CrossValidatorModel\n",
        "\n",
        "#initialize our grid -> we are using variation with only one parameter called maxIter (maximum iteration)\n",
        "grid = ParamGridBuilder().addGrid(dt.maxDepth, [2]).build()\n",
        "\n",
        "#CrossValidator will by default have 3 folds. We can explicitly specify that using numFolds = 3\n",
        "cv = CrossValidator(estimator=dt, estimatorParamMaps=grid, evaluator=evaluator_A, parallelism=2)\n",
        "\n",
        "#lets fit again on our training set\n",
        "cvModel = cv.fit(df_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7T-HNHNV_Ctm",
        "outputId": "10b4105a-dc40-4260-9974-64a88ecca110"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6958035292181495]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "#average metrics on 4 different models \n",
        "cvModel.avgMetrics \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hu7Fipjj_Ctm",
        "outputId": "cebe320f-5628-4c2a-b5ee-82fc04b17de9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6958812452421972"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "#lets try to get the accuracy of our model on the testing set\n",
        "evaluator_A.evaluate(cvModel.transform(df_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YboDVey_Ctn"
      },
      "outputs": [],
      "source": [
        "# Add your steps here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTXVWTI6pM1Q"
      },
      "source": [
        "# ML Pipeline for Best Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "DvFjydhN_Ctn"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml import Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "w2LyCJz2_Cto"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline(stages=[rf])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "G_uJ78I2_Cto"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Fit the pipeline to training documents.\n",
        "model = pipeline.fit(df_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTkALjLbV3Wc",
        "outputId": "5830c152-4561-438a-f29e-a7de35386a0c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6959546990397585"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "#lets try to get the accuracy of our model on the testing set\n",
        "evaluator_A.evaluate(model.transform(df_test))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}