{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jn4Ry97ScEhT",
    "outputId": "f1e7d3be-14fb-4922-ffab-ff9fb2df6a6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "connect to drive "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mHyPnM3G_Ctb"
   },
   "source": [
    "## Importing Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-y3RQvtkOjqp",
    "outputId": "2aabbbea-ce77-4b6e-eb4e-77edaa160ae5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pyspark\n",
      "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 281.4 MB 39 kB/s \n",
      "\u001b[?25hCollecting py4j==0.10.9.5\n",
      "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
      "\u001b[K     |████████████████████████████████| 199 kB 48.1 MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=db40e2a18771679bd07e30caa2d4e2bf85cc1ab1f2d1d4b55c2f9ead00b4783e\n",
      "  Stored in directory: /root/.cache/pip/wheels/43/dc/11/ec201cd671da62fa9c5cc77078235e40722170ceba231d7598\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark # install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "y7dQc4oDc0fz"
   },
   "outputs": [],
   "source": [
    "#import libary\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import sklearn \n",
    "\n",
    "#spark libary\n",
    "import pyspark\n",
    "from pyspark.sql import types\n",
    "from pyspark.sql.functions import col, isnan, when, count, explode, array, lit\n",
    "from pyspark.sql.types import FloatType #to change type to float\n",
    "from pyspark.sql.types import IntegerType #to change type to integer\n",
    "#import spark feature libary\n",
    "from pyspark.ml.feature import Imputer, VectorAssembler, StringIndexer\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "#import classfication model libary\n",
    "# Import some classifiers and multiclass evaluator\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier, LogisticRegression, GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline#pipline\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, CrossValidatorModel\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XbFzxDVL_Ctd"
   },
   "source": [
    "## Loading Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "imolJzaCJnno"
   },
   "outputs": [],
   "source": [
    "pandadf = pd.read_csv('/content/drive/MyDrive/cleaning_data 2.csv') #read ssv file as pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y228EzriOTcl"
   },
   "source": [
    "## connect to  spark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "f2Y-Wp34QG2H"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession # import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "aMmoIDWkOTcm"
   },
   "outputs": [],
   "source": [
    "#connect spark\n",
    "spark = pyspark.sql.SparkSession.builder.config(\"spark.executor.memory\", \"16g\").config(\"spark.driver.memory\", \"16g\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "aVBeM9g7RF53"
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "LZFmIzUUNex1"
   },
   "outputs": [],
   "source": [
    "#convert from pandas to spark\n",
    "df = spark.createDataFrame(pandadf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xeIq9PWLaGof",
    "outputId": "3d584b97-0714-4a87-eaaf-91f89a75ecd0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[restaurant_name: string, country: string, region: string, city: string, latitude: double, longitude: double, claimed: string, popularity_detailed: string, popularity_generic: string, cuisines: string, vegetarian_friendly: bigint, vegan_options: bigint, gluten_free: bigint, open_days_per_week: bigint, open_hours_per_week: double, working_shifts_per_week: bigint, avg_rating: double, total_reviews_count: bigint, default_language: string, reviews_count_in_default_language: bigint, excellent: double, very_good: double, average: double, poor: double, terrible: double, food: double, service: double, value: double, atmosphere: double, price_range: string]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SHOW DATA\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2gybrRtYyIFP",
    "outputId": "e2de4b44-f2e0-44c5-d498-714a05069eb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset:  (749544, 30)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of the dataset: ',(df.count(), len(df.columns)))# number of rows and coloumn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the dataset contain 30 columns and 749544 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKG4whcF_Cti"
   },
   "source": [
    "## Feature Engineering and Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yLzES1neOTdM",
    "outputId": "bdd9c0e5-0019-4b46-e3bc-6c9d9f2992ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- restaurant_name: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- claimed: string (nullable = true)\n",
      " |-- popularity_detailed: string (nullable = true)\n",
      " |-- popularity_generic: string (nullable = true)\n",
      " |-- cuisines: string (nullable = true)\n",
      " |-- vegetarian_friendly: long (nullable = true)\n",
      " |-- vegan_options: long (nullable = true)\n",
      " |-- gluten_free: long (nullable = true)\n",
      " |-- open_days_per_week: long (nullable = true)\n",
      " |-- open_hours_per_week: double (nullable = true)\n",
      " |-- working_shifts_per_week: long (nullable = true)\n",
      " |-- avg_rating: double (nullable = true)\n",
      " |-- total_reviews_count: long (nullable = true)\n",
      " |-- default_language: string (nullable = true)\n",
      " |-- reviews_count_in_default_language: long (nullable = true)\n",
      " |-- excellent: double (nullable = true)\n",
      " |-- very_good: double (nullable = true)\n",
      " |-- average: double (nullable = true)\n",
      " |-- poor: double (nullable = true)\n",
      " |-- terrible: double (nullable = true)\n",
      " |-- food: double (nullable = true)\n",
      " |-- service: double (nullable = true)\n",
      " |-- value: double (nullable = true)\n",
      " |-- atmosphere: double (nullable = true)\n",
      " |-- price_range: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()#show "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split avg_rating to 3 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "M9kdQlj2_Cti"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "spark = data.replace( [1.0,1.5,2.0,2.5] , 0, subset=[\"avg_rating\"]) #replace avg_rating  values 1-2.5 to 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "GuUaBz1jTyWk"
   },
   "outputs": [],
   "source": [
    "spark = spark.replace([3,3.5,4.0] , 1, subset=[\"avg_rating\"]) #replace avg_rating values 3-4 to 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ipMZCgtefadg"
   },
   "outputs": [],
   "source": [
    "spark = spark.replace([4.5,5.0] , 2, subset=[\"avg_rating\"]) #replace avg_rating values 4.5 -5 to 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert type for some column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "y1qVG3jnt4EK"
   },
   "outputs": [],
   "source": [
    "spark = spark.withColumn(\"vegetarian_friendly\", spark[\"vegetarian_friendly\"].cast(IntegerType())) #convert vegetarian_friendly type to  int type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "F7rz59Uxw2aZ"
   },
   "outputs": [],
   "source": [
    "spark = spark.withColumn(\"avg_rating\", spark[\"avg_rating\"].cast(IntegerType())) #convert avg_rating type to  int type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "qnnLs5YPt4Ri"
   },
   "outputs": [],
   "source": [
    "spark = spark.withColumn(\"vegan_options\", spark[\"vegan_options\"].cast(IntegerType())) #convert vegan_options type to  int type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "1zy9UhXtuclM"
   },
   "outputs": [],
   "source": [
    "spark = spark.withColumn(\"reviews_count_in_default_language\", spark[\"reviews_count_in_default_language\"].cast(IntegerType())) #convert reviews_count_in_default_language type to  int type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qm4u7wyAwFG9",
    "outputId": "0524623c-88de-4447-f1b5-6dfcddfedeb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|avg_rating| count|\n",
      "+----------+------+\n",
      "|         1|408493|\n",
      "|         2|313881|\n",
      "|         0| 27150|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.groupBy(\"avg_rating\").count().show()#check \n",
    "\n",
    "## - Baseline --> is 1 --> would be accurate by (408493/749544)*100 = 54%\n",
    "## - Whenever we build a model it needs to be more accurate than 54% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zz2fw3Iuhiok"
   },
   "source": [
    "### convert unbalance data to balance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wcdVfweGuhAA",
    "outputId": "a0ff618f-bee1-43b4-ed47-b641d0561a09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio: 11\n"
     ]
    }
   ],
   "source": [
    "major_df = spark.filter(col(\"avg_rating\") == 2)\n",
    "minor_df = spark.filter(col(\"avg_rating\") == 0)\n",
    "major2_df = spark.filter(col(\"avg_rating\") == 1)\n",
    "\n",
    "\n",
    "\n",
    "#we will calculate the ratio to determine the difference between the number of avg_rating 1 and avg_rating 0 transactions.\n",
    "ratio = int(major_df.count()/minor_df.count())\n",
    "print(\"ratio: {}\".format(ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "5ThS7QkFxWGm"
   },
   "outputs": [],
   "source": [
    "#create a range on this ratio and store it in variable a\n",
    "a = range(ratio)\n",
    "\n",
    "#duplicate the minority rows\n",
    "oversampled_df = minor_df.withColumn(\"dummy\", explode(array([lit(x) for x in a]))).drop('dummy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hAG5iqrUxacf",
    "outputId": "77c0f831-09e3-4d9e-a6fc-bc1e173c2a76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298650"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oversampled_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class 0 oversampling and now 298650"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "GeZPFK5jxgDn"
   },
   "outputs": [],
   "source": [
    "combined = major_df.unionAll(oversampled_df)\n",
    "\n",
    "combined_df = combined.unionAll(major2_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eHlQBYEFOTdN",
    "outputId": "d25e837c-2674-452d-85e1-148b95b541d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- restaurant_name: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- claimed: string (nullable = true)\n",
      " |-- popularity_detailed: string (nullable = true)\n",
      " |-- popularity_generic: string (nullable = true)\n",
      " |-- cuisines: string (nullable = true)\n",
      " |-- vegetarian_friendly: integer (nullable = true)\n",
      " |-- vegan_options: integer (nullable = true)\n",
      " |-- gluten_free: long (nullable = true)\n",
      " |-- open_days_per_week: long (nullable = true)\n",
      " |-- open_hours_per_week: double (nullable = true)\n",
      " |-- working_shifts_per_week: long (nullable = true)\n",
      " |-- avg_rating: integer (nullable = true)\n",
      " |-- total_reviews_count: long (nullable = true)\n",
      " |-- default_language: string (nullable = true)\n",
      " |-- reviews_count_in_default_language: integer (nullable = true)\n",
      " |-- excellent: double (nullable = true)\n",
      " |-- very_good: double (nullable = true)\n",
      " |-- average: double (nullable = true)\n",
      " |-- poor: double (nullable = true)\n",
      " |-- terrible: double (nullable = true)\n",
      " |-- food: double (nullable = true)\n",
      " |-- service: double (nullable = true)\n",
      " |-- value: double (nullable = true)\n",
      " |-- atmosphere: double (nullable = true)\n",
      " |-- price_range: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "a98akuS8Rs7p"
   },
   "outputs": [],
   "source": [
    "#This step will label encode all the categorical columns and store them in different columns with the same name + '_idx', \n",
    "#so category will become category_idx \n",
    "cat_cols = ['price_range','cuisines','claimed'] #cuisines and price_range\n",
    "\n",
    "#StringIndexer() is equivalent to LabelEncoder()\n",
    "for c in cat_cols: \n",
    "    indexer = StringIndexer(inputCol=c, outputCol=c+'_idx') #we pass the columns from the list as input one by one\n",
    "    combined_df = indexer.fit(combined_df).transform(combined_df) #here we fit and transform the data altogether\n",
    "    \n",
    "final_df2 = combined_df.drop(*cat_cols) #we will drop all the categorical columns we defined earlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ab_SFd3Lse5F"
   },
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "p8cL4m6vRs7q"
   },
   "outputs": [],
   "source": [
    "#drop unneed columns\n",
    "\n",
    "final_df=final_df2.drop('service','value','average','reviews_count_in_default_language','price_range', 'atmosphere','default_language','working_shifts_per_week','open_hours_per_week','open_days_per_week','popularity_generic','popularity_detailed','longitude','latitude','region','city','country','restaurant_name')\n",
    "\n",
    "cols = final_df.columns #extract the column names from the dataframe\n",
    "cols.remove('avg_rating') #remove avg_rating -> we need this to be our label\n",
    "\n",
    "#vector assembler will take all the columns and convert them into one column called features\n",
    "assembler = VectorAssembler(inputCols=cols, outputCol='features')\n",
    "\n",
    "#the .transform will apply the changes here\n",
    "final_df = assembler.transform(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3om2mKmdOTdO",
    "outputId": "a66d2b0e-f66d-4140-f172-539e8a83c5e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[vegetarian_friendly: int, vegan_options: int, gluten_free: bigint, avg_rating: int, total_reviews_count: bigint, excellent: double, very_good: double, poor: double, terrible: double, food: double, price_range_idx: double, cuisines_idx: double, claimed_idx: double, features: vector]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we can now see that features column will appear within the dataframe\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eEXpo5yfOTdO"
   },
   "source": [
    "\n",
    "Lets Split\n",
    "\n",
    "80% in training set and 20% is testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "UAAWTr8qOTdP"
   },
   "outputs": [],
   "source": [
    "# We will now create a new dataframe only consisting of the features column and the label column (actually stars column but renamed)\n",
    "df_data = final_df.select(col('features'), col('avg_rating').alias('label'))\n",
    "\n",
    "#simple data splitting\n",
    "df_train, df_test = df_data.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTwkfOrWswkW"
   },
   "source": [
    "## Train Models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFK296zBug7u"
   },
   "source": [
    "### 1st  Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "2z4OBK9SOTdQ"
   },
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\" ,maxDepth=5,maxBins=800000)\n",
    "model_dt = dt.fit(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvFI9DEtuXvw"
   },
   "source": [
    "### 2nd  Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "GAoyDH5-u1PZ"
   },
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=8,maxDepth=5 ,maxBins=750000)\n",
    "model_rf = rf.fit(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ke8DFgiHu_WK"
   },
   "source": [
    "### 3rd  Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "cicu5WyGvWGy"
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8, labelCol=\"label\", featuresCol=\"features\")\n",
    "model_lr = lr.fit(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZ1MNVthFaUc"
   },
   "source": [
    "### 4  Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "KYSMcpLeRs7t"
   },
   "outputs": [],
   "source": [
    "#NaiveBayes\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "nb = NaiveBayes(smoothing=1.0, \n",
    "                modelType=\"gaussian\", \n",
    "                featuresCol='features', labelCol='label')\n",
    "model_niv = nb.fit(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xdLl8k9_wG6v"
   },
   "source": [
    "## Model Evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EUP0fJJdvmQj"
   },
   "source": [
    "### 1st Model  Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "ITE4LHiQvuIh"
   },
   "outputs": [],
   "source": [
    "#  DT .transform\n",
    "pred_dt = model_dt.transform(df_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WewFtASjFaUk"
   },
   "source": [
    "## report  and matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zj_ecisd_Ctk",
    "outputId": "efa97cd5-ece1-4448-b6be-059c07b00ad0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.85     59810\n",
      "           1       0.81      0.65      0.72     82152\n",
      "           2       0.76      0.86      0.81     62698\n",
      "\n",
      "    accuracy                           0.79    204660\n",
      "   macro avg       0.79      0.80      0.79    204660\n",
      "weighted avg       0.79      0.79      0.78    204660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#report\n",
    "y_true = pred_dt.select(['label']).collect()\n",
    "y_pred = pred_dt.select(['prediction']).collect()\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of D tree is .79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3AjaooPAkHgw",
    "outputId": "6e054131-5820-4377-a038-9713e896e4db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[53642  5211   957]\n",
      " [12160 53532 16460]\n",
      " [ 1213  7328 54157]]\n"
     ]
    }
   ],
   "source": [
    "#matrix\n",
    "from sklearn import metrics\n",
    "matrix=metrics.confusion_matrix(y_true,y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dadYirzrzGip"
   },
   "source": [
    "### 2nd Model  Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "W_xtasIr_Ctl"
   },
   "outputs": [],
   "source": [
    "# random forst.transform\n",
    "pred_rf = model_rf.transform(df_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mnwakwvlFaUl"
   },
   "source": [
    "## report  and matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XZf3SMe2_Ctl",
    "outputId": "680ed395-d447-4a87-e3e2-b6009a3bf814"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.87     59810\n",
      "           1       0.83      0.68      0.74     82152\n",
      "           2       0.77      0.86      0.81     62698\n",
      "\n",
      "    accuracy                           0.80    204660\n",
      "   macro avg       0.81      0.82      0.81    204660\n",
      "weighted avg       0.81      0.80      0.80    204660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_true3 = pred_rf.select(['label']).collect()\n",
    "y_pred3 = pred_rf.select(['prediction']).collect()\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_true3, y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of Random forst is .80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ou5ZxNR1kOwQ",
    "outputId": "a09b71bf-dee0-4c3c-e0f6-8cf9a58c374d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[55083  3920   807]\n",
      " [11450 55495 15207]\n",
      " [  843  7727 54128]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "matrix=metrics.confusion_matrix(y_true3,y_pred3)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JhqUCJrNznO6"
   },
   "source": [
    "### 3rd Model  Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "nn0OzB2G_Ctl"
   },
   "outputs": [],
   "source": [
    "# Logistic .transform\n",
    "pred_lr = model_lr.transform(df_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JTQkkR-FaUp"
   },
   "source": [
    "## report  and matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7-fZns6Hic28",
    "outputId": "4b4c895a-c2d8-47b8-bda9-657078819a49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.01     59810\n",
      "           1       0.40      1.00      0.57     82152\n",
      "           2       0.00      0.00      0.00     62698\n",
      "\n",
      "    accuracy                           0.40    204660\n",
      "   macro avg       0.47      0.33      0.19    204660\n",
      "weighted avg       0.45      0.40      0.23    204660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true4 = pred_lr.select(['label']).collect()\n",
    "y_pred4 = pred_lr.select(['prediction']).collect()\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_true4, y_pred4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of Logistic is .40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PuZcXT_yj6ib",
    "outputId": "771c279f-d602-4530-e965-a2e96f430b4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  159 59651     0]\n",
      " [    0 82152     0]\n",
      " [    0 62698     0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "matrix=metrics.confusion_matrix(y_true4,y_pred4)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N9xRPPwlOTdo"
   },
   "source": [
    "### 4th Model  Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "K1N_NxawRs7v"
   },
   "outputs": [],
   "source": [
    "#NaiveBayes\n",
    "pred_nb = model_niv.transform(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U87LdQfVFaUv"
   },
   "source": [
    "## report  and matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ThDvggnDikx_",
    "outputId": "d20426d9-9a7e-4640-9fd0-19a4b2dfd85d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.96      0.56     59810\n",
      "           1       0.82      0.15      0.26     82152\n",
      "           2       0.64      0.44      0.52     62698\n",
      "\n",
      "    accuracy                           0.48    204660\n",
      "   macro avg       0.62      0.52      0.45    204660\n",
      "weighted avg       0.64      0.48      0.43    204660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true6 = pred_nb.select(['label']).collect()\n",
    "y_pred6 = pred_nb.select(['prediction']).collect()\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_true6, y_pred6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of NaiveBayes is .48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ge1ZeMFgjvZd",
    "outputId": "810ebd59-fb8a-4933-8d37-7ac472b64aa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[57535  1556   719]\n",
      " [54502 12719 14931]\n",
      " [33682  1189 27827]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "matrix=metrics.confusion_matrix(y_true6,y_pred6)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3Qt31q9OTdp"
   },
   "source": [
    "## Show ML Evaluation as Dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "O0qIeaoFOTdp"
   },
   "outputs": [],
   "source": [
    "# Accuracy Metric\n",
    "evaluator_A = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "# F1 Metric\n",
    "evaluator_F = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "# Weighted Precision\n",
    "evaluator_P = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "\n",
    "# Weighted Recall\n",
    "evaluator_R = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "\n",
    "# Our models\n",
    "models = [pred_dt, pred_rf, pred_lr,pred_nb]\n",
    "\n",
    "# Empty lists that will store the scores for each metric for each model.\n",
    "accuracy = []\n",
    "F1 = []\n",
    "precision = []\n",
    "recall = []\n",
    "\n",
    "# Simple loop to populate the empty lists with scores of models for each metric.\n",
    "for model in models:\n",
    "    accuracy.append(evaluator_A.evaluate(model))\n",
    "    F1.append(evaluator_F.evaluate(model))\n",
    "    precision.append(evaluator_P.evaluate(model))\n",
    "    recall.append(evaluator_R.evaluate(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "lu-KfupAOTdq"
   },
   "outputs": [],
   "source": [
    "# We will convert all lists created above into a dataframe for easy viewing.\n",
    "df_ev = pd.DataFrame(list(zip(accuracy, F1, precision, recall)), \n",
    "                     columns = ['Accuracy', 'F1-Score', 'Weighted Precision', 'Weighted Recall'],\n",
    "                     index = ['Decision Tree', 'Random Forest', 'Logistic Regression','nive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "PFmrj7FnOTdq",
    "outputId": "746c068d-bac7-4bd4-c633-e5346fe18079"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-bd9023be-4e04-418d-aae4-4b7b0460d288\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Weighted Precision</th>\n",
       "      <th>Weighted Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.788288</td>\n",
       "      <td>0.784283</td>\n",
       "      <td>0.790955</td>\n",
       "      <td>0.788288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.804779</td>\n",
       "      <td>0.801209</td>\n",
       "      <td>0.807106</td>\n",
       "      <td>0.804779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.402184</td>\n",
       "      <td>0.231629</td>\n",
       "      <td>0.453494</td>\n",
       "      <td>0.402184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nive</th>\n",
       "      <td>0.479239</td>\n",
       "      <td>0.428802</td>\n",
       "      <td>0.641618</td>\n",
       "      <td>0.479239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd9023be-4e04-418d-aae4-4b7b0460d288')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-bd9023be-4e04-418d-aae4-4b7b0460d288 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-bd9023be-4e04-418d-aae4-4b7b0460d288');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                     Accuracy  F1-Score  Weighted Precision  Weighted Recall\n",
       "Decision Tree        0.788288  0.784283            0.790955         0.788288\n",
       "Random Forest        0.804779  0.801209            0.807106         0.804779\n",
       "Logistic Regression  0.402184  0.231629            0.453494         0.402184\n",
       "nive                 0.479239  0.428802            0.641618         0.479239"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceobXQ5CdiU1"
   },
   "source": [
    "the best model is random tree with 0.80 Accuracy , and the worest model is Logistic Regression\t with 0.40 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CO53Znc6d-4g"
   },
   "source": [
    "## select  best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47wixViTcUOe"
   },
   "source": [
    "Random Forst is the best model with accurcy 0.80 and \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Tuning for Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "wy9jQnQDwpKz"
   },
   "outputs": [],
   "source": [
    "\n",
    "#initialize our grid -> we are using variation with only one parameter called maxIter (maximum iteration)\n",
    "grid = ParamGridBuilder().addGrid(rf.maxDepth, [5,6]).build()\n",
    "\n",
    "#CrossValidator will by default have 3 folds. \n",
    "cv = CrossValidator(estimator=rf, estimatorParamMaps=grid, evaluator=evaluator_A, parallelism=2)\n",
    "\n",
    "#lets fit again on our training set\n",
    "cvModel = cv.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p-KtJZS8wpVg",
    "outputId": "914f1982-1f2f-4cf2-ac1b-12fb00b0f688"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8056909650786443, 0.8191410400491006]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#average metrics on 4 different models \n",
    "cvModel.avgMetrics \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rLByaMgqwpX7",
    "outputId": "c9926768-927d-4cd1-a1ed-d658e5cbcfb1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8252858399296394"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets try to get the accuracy of our model on the testing set\n",
    "evaluator_A.evaluate(cvModel.transform(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after apply grid the accuracy is 82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vTXVWTI6pM1Q"
   },
   "source": [
    "# ML Pipeline for Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w2LyCJz2_Cto"
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[rf])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G_uJ78I2_Cto"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Fit the pipeline to training documents.\n",
    "model = pipeline.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nTkALjLbV3Wc",
    "outputId": "fbad4ae8-1140-4127-dbe7-fbe1007104e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8019790846733386"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets try to get the accuracy of our model on the testing set\n",
    "evaluator_A.evaluate(model.transform(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after apply pipeline the accuracy is 80"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
