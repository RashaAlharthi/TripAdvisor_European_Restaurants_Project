{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mHyPnM3G_Ctb"
   },
   "source": [
    "## Importing Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-y3RQvtkOjqp",
    "outputId": "6e2f74d5-2267-4f61-e10e-135b5e1b1ab3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pyspark\n",
      "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 281.4 MB 47 kB/s \n",
      "\u001b[?25hCollecting py4j==0.10.9.5\n",
      "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
      "\u001b[K     |████████████████████████████████| 199 kB 63.0 MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=72ee22ea9a0bd5a7ce9e397e20153ec200778b26988da5f90a6f65f6d20a0575\n",
      "  Stored in directory: /root/.cache/pip/wheels/43/dc/11/ec201cd671da62fa9c5cc77078235e40722170ceba231d7598\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "y7dQc4oDc0fz"
   },
   "outputs": [],
   "source": [
    "#import libary\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import types\n",
    "from pyspark.sql.functions import col, isnan, when, count, explode, array, lit\n",
    "\n",
    "# Import some classifiers and multiclass evaluator\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier, LogisticRegression, GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "#feature libary\n",
    "from pyspark.ml.feature import Imputer, VectorAssembler, StringIndexer\n",
    "from pyspark.ml.classification import FMClassifier\n",
    "#import evaluation\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "#TO convert type\n",
    "from pyspark.sql.types import IntegerType \n",
    "from pyspark.sql.types import FloatType \n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XbFzxDVL_Ctd"
   },
   "source": [
    "## Loading Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Uj4YuXAjlH-A"
   },
   "outputs": [],
   "source": [
    "pandadf = pd.read_csv('/content/drive/MyDrive/cleaning_data.csv') #read ssv file as pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y228EzriOTcl"
   },
   "source": [
    "## connect to  spark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession # import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "aMmoIDWkOTcm"
   },
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.config(\"spark.executor.memory\", \"16g\").config(\"spark.driver.memory\", \"16g\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert from pandas to spark\n",
    "df = spark.createDataFrame(pandadf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKG4whcF_Cti"
   },
   "source": [
    "## Feature Engineering and Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "CTt0b2-Oa6dc"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "spark_df = data3.replace( \"Unclaimed\" , '0', subset=[\"claimed\"]) #replace Unclaimed to 0\n",
    " spark_df= spark_df.replace( \"Claimed\" , '1', subset=[\"claimed\"]) #replace claimed to 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert some columns types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "WFpvRP4dpHKF"
   },
   "outputs": [],
   "source": [
    "spark = spark_df.withColumn(\"claimed\", spark_df[\"claimed\"].cast(FloatType())) #convert claimed type to  int type\n",
    "spark = spark.withColumn(\"vegetarian_friendly\", spark[\"vegetarian_friendly\"].cast(IntegerType())) #convert vegetarian_friendly type to  int type\n",
    "spark = spark.withColumn(\"avg_rating\", spark[\"avg_rating\"].cast(IntegerType())) #convert avg_rating type to  int type\n",
    "spark = spark.withColumn(\"vegan_options\", spark[\"vegan_options\"].cast(IntegerType())) #convert vegan_options type to  int type\n",
    "spark = spark.withColumn(\"reviews_count_in_default_language\", spark[\"reviews_count_in_default_language\"].cast(IntegerType())) #convert reviews_count_in_default_language type to  int type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "YDxi3xXMkez1"
   },
   "outputs": [],
   "source": [
    "#new pyspark frame\n",
    "combined_df=spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "a98akuS8Rs7p"
   },
   "outputs": [],
   "source": [
    "#This step will label encode all the categorical columns and store them in different columns with the same name + '_idx', \n",
    "#so category will become category_idx \n",
    "cat_cols = ['price_range']\n",
    "\n",
    "#StringIndexer() is equivalent to LabelEncoder()\n",
    "for c in cat_cols: \n",
    "    indexer = StringIndexer(inputCol=c, outputCol=c+'_idx') #we pass the columns from the list as input one by one\n",
    "    combined_df = indexer.fit(combined_df).transform(combined_df) #here we fit and transform the data altogether\n",
    "    \n",
    "final_df2 = combined_df.drop(*cat_cols) #we will drop all the categorical columns we defined earlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ab_SFd3Lse5F"
   },
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "p8cL4m6vRs7q"
   },
   "outputs": [],
   "source": [
    "#drop unneed columns\n",
    "\n",
    "final_df=final_df2.drop('avg_rating','average', 'atmosphere','default_language','working_shifts_per_week','open_hours_per_week','open_days_per_week','cuisines','popularity_generic','popularity_detailed','longitude','latitude','region','city','country','restaurant_name')\n",
    "\n",
    "cols = final_df.columns #extract the column names from the dataframe\n",
    "cols.remove('claimed') #remove claimed -> we need this to be our label\n",
    "\n",
    "#vector assembler will take all the columns and convert them into one column called features\n",
    "assembler = VectorAssembler(inputCols=cols, outputCol='features')\n",
    "\n",
    "#the .transform will apply the changes here\n",
    "final_df = assembler.transform(final_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eEXpo5yfOTdO"
   },
   "source": [
    "\n",
    "Lets Split\n",
    "\n",
    "80% in training set and 20% is testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "UAAWTr8qOTdP"
   },
   "outputs": [],
   "source": [
    "# We will now create a new dataframe only consisting of the features column and the label column (actually claimed column but renamed)\n",
    "df_data = final_df.select(col('features'), col('claimed').alias('label'))\n",
    "\n",
    "#simple data splitting\n",
    "df_train, df_test = df_data.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTwkfOrWswkW"
   },
   "source": [
    "## Train Models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFK296zBug7u"
   },
   "source": [
    "### 1st  Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "2z4OBK9SOTdQ"
   },
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\" ,maxBins=800000)\n",
    "model_dt = dt.fit(df_train)#fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvFI9DEtuXvw"
   },
   "source": [
    "### 2nd  Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "GAoyDH5-u1PZ"
   },
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=20,maxDepth=10 ,maxBins=800000)\n",
    "model_rf = rf.fit(df_train) #fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ke8DFgiHu_WK"
   },
   "source": [
    "### 3rd  Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "cicu5WyGvWGy"
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8, labelCol=\"label\", featuresCol=\"features\")\n",
    "model_lr = lr.fit(df_train)#fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9VR70nuOTdX"
   },
   "source": [
    "### 4th  Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HUETg6WSa4yD"
   },
   "outputs": [],
   "source": [
    "# Gradient Boost\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\", maxIter=10)\n",
    "model_gbt = gbt.fit(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QiydJJ5DFaUd"
   },
   "source": [
    "### 5  Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KYSMcpLeRs7t"
   },
   "outputs": [],
   "source": [
    "#NaiveBayes\n",
    "nb = NaiveBayes(smoothing=1.0, \n",
    "                modelType=\"gaussian\", \n",
    "                featuresCol='features', labelCol='label')\n",
    "model_niv = nb.fit(df_train)#fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6  Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = FMClassifier(labelCol=\"label\", featuresCol=\"features\", stepSize=0.001)\n",
    "model_fm = em.fit(df_train)#fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xdLl8k9_wG6v"
   },
   "source": [
    "## Model Evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EUP0fJJdvmQj"
   },
   "source": [
    "### 1st Model  Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "ITE4LHiQvuIh"
   },
   "outputs": [],
   "source": [
    "#D tree\n",
    "pred_dt = model_dt.transform(df_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WewFtASjFaUk"
   },
   "source": [
    "## report  and matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zj_ecisd_Ctk",
    "outputId": "37140eb9-deca-4bf7-e868-019bb699c063"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.63      0.63     65367\n",
      "         1.0       0.71      0.71      0.71     84482\n",
      "\n",
      "    accuracy                           0.68    149849\n",
      "   macro avg       0.67      0.67      0.67    149849\n",
      "weighted avg       0.68      0.68      0.68    149849\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#report\n",
    "import sklearn \n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "y_true = pred_dt.select(['label']).collect()\n",
    "y_pred = pred_dt.select(['prediction']).collect()\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy for Decision Tree is 68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3AjaooPAkHgw",
    "outputId": "fdcb54b6-bad4-4b07-8391-9b8e15e7d23e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[106 167]\n",
      " [ 71 343]]\n"
     ]
    }
   ],
   "source": [
    "#matrix\n",
    "from sklearn import metrics\n",
    "matrix=metrics.confusion_matrix(y_true,y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dadYirzrzGip"
   },
   "source": [
    "### 2nd Model  Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "W_xtasIr_Ctl"
   },
   "outputs": [],
   "source": [
    "#  random forst tree\n",
    "pred_rf = model_rf.transform(df_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mnwakwvlFaUl"
   },
   "source": [
    "## report  and matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XZf3SMe2_Ctl",
    "outputId": "baa7eb3a-cf1f-4842-9e03-8e1fa5412229",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.68      0.65     65367\n",
      "         1.0       0.74      0.70      0.72     84482\n",
      "\n",
      "    accuracy                           0.69    149849\n",
      "   macro avg       0.68      0.69      0.69    149849\n",
      "weighted avg       0.69      0.69      0.69    149849\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_true3 = pred_rf.select(['label']).collect()\n",
    "y_pred3 = pred_rf.select(['prediction']).collect()\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_true3, y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy for rando forst is 0.69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ou5ZxNR1kOwQ",
    "outputId": "c0467c30-2553-4d80-c9aa-0be7e2bfd9dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 99 174]\n",
      " [ 72 342]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "matrix=metrics.confusion_matrix(y_true3,y_pred3)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JhqUCJrNznO6"
   },
   "source": [
    "### 3rd Model  Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "nn0OzB2G_Ctl"
   },
   "outputs": [],
   "source": [
    "# Logistic Regression transform\n",
    "pred_lr = model_lr.transform(df_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JTQkkR-FaUp"
   },
   "source": [
    "## report  and matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7-fZns6Hic28",
    "outputId": "10dc9d5e-98ee-4337-b59d-41ab0953ddb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00     65367\n",
      "         1.0       0.56      1.00      0.72     84482\n",
      "\n",
      "    accuracy                           0.56    149849\n",
      "   macro avg       0.28      0.50      0.36    149849\n",
      "weighted avg       0.32      0.56      0.41    149849\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true4 = pred_lr.select(['label']).collect()\n",
    "y_pred4 = pred_lr.select(['prediction']).collect()\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_true4, y_pred4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy for  Logistic Regression is 0.56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PuZcXT_yj6ib",
    "outputId": "20593b59-0017-4e75-b079-1a97d54020c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 273]\n",
      " [  0 414]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "matrix=metrics.confusion_matrix(y_true4,y_pred4)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N9xRPPwlOTdo"
   },
   "source": [
    "### 4th Model  Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mNjKMpSGOTdp"
   },
   "outputs": [],
   "source": [
    "#   Gradient Boost\n",
    "\n",
    "pred_gbt = model_gbt.transform(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nt8xqTeqFaUt"
   },
   "source": [
    "## report  and matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ODbbaXRyijUk",
    "outputId": "d9181568-4d7a-4d5b-bbe2-ab2498d4bd90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.42      0.50       273\n",
      "           1       0.69      0.83      0.75       414\n",
      "\n",
      "    accuracy                           0.67       687\n",
      "   macro avg       0.65      0.63      0.63       687\n",
      "weighted avg       0.66      0.67      0.65       687\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true5 = pred_gbt.select(['label']).collect()\n",
    "y_pred5 = pred_gbt.select(['prediction']).collect()\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_true5, y_pred5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "accuracy for  Gradient Boost is 0.67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "anLD685Gkhi2",
    "outputId": "d68b0b1f-c73d-428e-a145-1ca801b2bc22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[116 157]\n",
      " [ 72 342]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "matrix=metrics.confusion_matrix(y_true5,y_pred5)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OrDS6f-lFaUv"
   },
   "source": [
    "## 5th Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K1N_NxawRs7v"
   },
   "outputs": [],
   "source": [
    "#NaiveBayes\n",
    "\n",
    "pred_nb = model_niv.transform(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U87LdQfVFaUv"
   },
   "source": [
    "## report  and matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ThDvggnDikx_",
    "outputId": "ae6a3c14-0c5a-4b49-a9e0-eb10887940f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.34      0.52      0.41       275\n",
      "         2.0       0.00      0.00      0.00       420\n",
      "\n",
      "    accuracy                           0.21       695\n",
      "   macro avg       0.11      0.17      0.14       695\n",
      "weighted avg       0.13      0.21      0.16       695\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true6 = pred_nb.select(['label']).collect()\n",
    "y_pred6 = pred_nb.select(['prediction']).collect()\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_true6, y_pred6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "accuracy for NaiveBayes is 0.21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ge1ZeMFgjvZd",
    "outputId": "7f498595-6e6f-4522-fe98-f80495f35efc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0]\n",
      " [131 144   0]\n",
      " [140 280   0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "matrix=metrics.confusion_matrix(y_true6,y_pred6)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKowP4A8FaUw"
   },
   "source": [
    "## 6 Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "osXGCT2NbE7n"
   },
   "outputs": [],
   "source": [
    "#Factorization machines classifier\n",
    "pred_fm = model_fm.transform(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fc_sb_KNFaUx"
   },
   "source": [
    "## report  and matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "amvKxLepil4b",
    "outputId": "e2d47df0-8a14-4938-c55b-9fddcd19c387"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       273\n",
      "           1       0.60      1.00      0.75       414\n",
      "\n",
      "    accuracy                           0.60       687\n",
      "   macro avg       0.30      0.50      0.38       687\n",
      "weighted avg       0.36      0.60      0.45       687\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true7 = pred_fm.select(['label']).collect()\n",
    "y_pred7 = pred_fm.select(['prediction']).collect()\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_true7, y_pred7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy for Factorization is 0.60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "accuracy for Factorization is 0.60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "exVU3tnJiz_S",
    "outputId": "78afa56a-cb39-4061-ba6b-315bc5d8e5fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 273]\n",
      " [  1 413]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "matrix=metrics.confusion_matrix(y_true7,y_pred7)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceobXQ5CdiU1"
   },
   "source": [
    "### The best model is random tree with 0.69 , and the worest model is nive with 0.21\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
