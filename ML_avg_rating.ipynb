{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vRBjG71s_Cta"
   },
   "source": [
    "\n",
    "***\n",
    "# Classification - ML Section\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mHyPnM3G_Ctb"
   },
   "source": [
    "## Importing Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-y3RQvtkOjqp",
    "outputId": "53d2886b-891d-49d5-c421-db1bd7769c49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pyspark\n",
      "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 281.4 MB 53 kB/s \n",
      "\u001b[?25hCollecting py4j==0.10.9.5\n",
      "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
      "\u001b[K     |████████████████████████████████| 199 kB 70.4 MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=587ebf0d1d43b6dfb4ae3d14f3dc1a056c8bc316dcdb6f07cf9a204d748530f6\n",
      "  Stored in directory: /root/.cache/pip/wheels/43/dc/11/ec201cd671da62fa9c5cc77078235e40722170ceba231d7598\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "y7dQc4oDc0fz"
   },
   "outputs": [],
   "source": [
    "#import libary\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import types\n",
    "from pyspark.sql.functions import col, isnan, when, count, explode, array, lit\n",
    "\n",
    "\n",
    "from pyspark.ml.feature import Imputer, VectorAssembler, StringIndexer\n",
    "from pyspark.ml.regression import RandomForestRegressor, DecisionTreeRegressor, GBTRegressor, LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "imolJzaCJnno"
   },
   "outputs": [],
   "source": [
    "pandadf = pd.read_csv('cleaning_data 2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y228EzriOTcl"
   },
   "source": [
    "## connect to  spark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "f2Y-Wp34QG2H"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "aMmoIDWkOTcm"
   },
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.config(\"spark.executor.memory\", \"16g\").config(\"spark.driver.memory\", \"16g\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "aVBeM9g7RF53"
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "LZFmIzUUNex1"
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(pandadf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XbFzxDVL_Ctd"
   },
   "source": [
    "## Loading Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xeIq9PWLaGof",
    "outputId": "1831a23f-f923-4a37-a72f-c78a7271a2d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[restaurant_name: string, country: string, region: string, city: string, latitude: double, longitude: double, claimed: string, popularity_detailed: string, popularity_generic: string, cuisines: string, vegetarian_friendly: bigint, vegan_options: bigint, gluten_free: bigint, open_days_per_week: bigint, open_hours_per_week: double, working_shifts_per_week: bigint, avg_rating: double, total_reviews_count: bigint, default_language: string, reviews_count_in_default_language: bigint, excellent: double, very_good: double, average: double, poor: double, terrible: double, food: double, service: double, value: double, atmosphere: double, price_range: string]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SHOW DATA\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X13TVCUlFaT4",
    "outputId": "9a3387f8-e8e5-4fdc-d73a-cbab1e5b9229"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset:  (749544, 30)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of the dataset: ',(df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6I0PCCySOTcu"
   },
   "source": [
    "## drop non values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "WWa_FzTuOTcu"
   },
   "outputs": [],
   "source": [
    "#drop all null valures\n",
    "data=df.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GP0G2Q-i_Cti"
   },
   "source": [
    "***\n",
    "# ML Classification Section \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKG4whcF_Cti"
   },
   "source": [
    "## Feature Engineering and Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yLzES1neOTdM",
    "outputId": "bdd9c0e5-0019-4b46-e3bc-6c9d9f2992ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- restaurant_name: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- claimed: string (nullable = true)\n",
      " |-- popularity_detailed: string (nullable = true)\n",
      " |-- popularity_generic: string (nullable = true)\n",
      " |-- cuisines: string (nullable = true)\n",
      " |-- vegetarian_friendly: long (nullable = true)\n",
      " |-- vegan_options: long (nullable = true)\n",
      " |-- gluten_free: long (nullable = true)\n",
      " |-- open_days_per_week: long (nullable = true)\n",
      " |-- open_hours_per_week: double (nullable = true)\n",
      " |-- working_shifts_per_week: long (nullable = true)\n",
      " |-- avg_rating: double (nullable = true)\n",
      " |-- total_reviews_count: long (nullable = true)\n",
      " |-- default_language: string (nullable = true)\n",
      " |-- reviews_count_in_default_language: long (nullable = true)\n",
      " |-- excellent: double (nullable = true)\n",
      " |-- very_good: double (nullable = true)\n",
      " |-- average: double (nullable = true)\n",
      " |-- poor: double (nullable = true)\n",
      " |-- terrible: double (nullable = true)\n",
      " |-- food: double (nullable = true)\n",
      " |-- service: double (nullable = true)\n",
      " |-- value: double (nullable = true)\n",
      " |-- atmosphere: double (nullable = true)\n",
      " |-- price_range: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()#show "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "M9kdQlj2_Cti"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import FloatType \n",
    "\n",
    "\n",
    "spark = data.replace( [1.0,1.5,2.0,2.5] , 0, subset=[\"avg_rating\"]) #replace avg_rating to 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "GuUaBz1jTyWk"
   },
   "outputs": [],
   "source": [
    "spark = spark.replace([3,3.5,4.0] , 1, subset=[\"avg_rating\"]) #replace avg_rating to 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "ipMZCgtefadg"
   },
   "outputs": [],
   "source": [
    "spark = spark.replace([4.5,5.0] , 2, subset=[\"avg_rating\"]) #replace avg_rating 3,4 to 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "WOQiv-kVt-av"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType #to change type to integer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "y1qVG3jnt4EK"
   },
   "outputs": [],
   "source": [
    "spark = spark.withColumn(\"vegetarian_friendly\", spark[\"vegetarian_friendly\"].cast(IntegerType())) #convert vegetarian_friendly type to  int type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "F7rz59Uxw2aZ"
   },
   "outputs": [],
   "source": [
    "spark = spark.withColumn(\"avg_rating\", spark[\"avg_rating\"].cast(IntegerType())) #convert avg_rating type to  int type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "qnnLs5YPt4Ri"
   },
   "outputs": [],
   "source": [
    "spark = spark.withColumn(\"vegan_options\", spark[\"vegan_options\"].cast(IntegerType())) #convert vegan_options type to  int type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "1zy9UhXtuclM"
   },
   "outputs": [],
   "source": [
    "spark = spark.withColumn(\"reviews_count_in_default_language\", spark[\"reviews_count_in_default_language\"].cast(IntegerType())) #convert reviews_count_in_default_language type to  int type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qm4u7wyAwFG9",
    "outputId": "ab61fb1a-f104-477b-be59-64df281c7b84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|avg_rating| count|\n",
      "+----------+------+\n",
      "|         1|408493|\n",
      "|         2|313881|\n",
      "|         0| 27150|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.groupBy(\"avg_rating\").count().show()#check \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert unbalance data to balance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wcdVfweGuhAA",
    "outputId": "656f3ae9-492d-4f48-916f-7704f6d40712"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio: 11\n"
     ]
    }
   ],
   "source": [
    "major_df = spark.filter(col(\"avg_rating\") == 2)\n",
    "minor_df = spark.filter(col(\"avg_rating\") == 0)\n",
    "major2_df = spark.filter(col(\"avg_rating\") == 1)\n",
    "\n",
    "\n",
    "\n",
    "#we will calculate the ratio to determine the difference between the number of avg_rating 1 and avg_rating 0 transactions.\n",
    "ratio = int(major_df.count()/minor_df.count())\n",
    "print(\"ratio: {}\".format(ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "5ThS7QkFxWGm"
   },
   "outputs": [],
   "source": [
    "#create a range on this ratio and store it in variable a\n",
    "a = range(ratio)\n",
    "\n",
    "#duplicate the minority rows\n",
    "oversampled_df = minor_df.withColumn(\"dummy\", explode(array([lit(x) for x in a]))).drop('dummy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hAG5iqrUxacf",
    "outputId": "6778c4c0-8719-43f2-c876-11ab641ff100"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298650"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oversampled_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "GeZPFK5jxgDn"
   },
   "outputs": [],
   "source": [
    "combined = major_df.unionAll(oversampled_df)\n",
    "\n",
    "combined_df = combined.unionAll(major2_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eHlQBYEFOTdN",
    "outputId": "d25e837c-2674-452d-85e1-148b95b541d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- restaurant_name: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- claimed: string (nullable = true)\n",
      " |-- popularity_detailed: string (nullable = true)\n",
      " |-- popularity_generic: string (nullable = true)\n",
      " |-- cuisines: string (nullable = true)\n",
      " |-- vegetarian_friendly: integer (nullable = true)\n",
      " |-- vegan_options: integer (nullable = true)\n",
      " |-- gluten_free: long (nullable = true)\n",
      " |-- open_days_per_week: long (nullable = true)\n",
      " |-- open_hours_per_week: double (nullable = true)\n",
      " |-- working_shifts_per_week: long (nullable = true)\n",
      " |-- avg_rating: integer (nullable = true)\n",
      " |-- total_reviews_count: long (nullable = true)\n",
      " |-- default_language: string (nullable = true)\n",
      " |-- reviews_count_in_default_language: integer (nullable = true)\n",
      " |-- excellent: double (nullable = true)\n",
      " |-- very_good: double (nullable = true)\n",
      " |-- average: double (nullable = true)\n",
      " |-- poor: double (nullable = true)\n",
      " |-- terrible: double (nullable = true)\n",
      " |-- food: double (nullable = true)\n",
      " |-- service: double (nullable = true)\n",
      " |-- value: double (nullable = true)\n",
      " |-- atmosphere: double (nullable = true)\n",
      " |-- price_range: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QJyQT4xAxrLY",
    "outputId": "015ea072-3058-4f9a-c2dc-f2a050a74bbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|avg_rating| count|\n",
      "+----------+------+\n",
      "|         2|313881|\n",
      "|         0|298650|\n",
      "|         1|408493|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined_df.groupBy(\"avg_rating\").count().show()#check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "a98akuS8Rs7p"
   },
   "outputs": [],
   "source": [
    "#This step will label encode all the categorical columns and store them in different columns with the same name + '_idx', \n",
    "#so category will become category_idx \n",
    "cat_cols = ['price_range','cuisines','claimed'] #cuisines and price_range\n",
    "\n",
    "#StringIndexer() is equivalent to LabelEncoder()\n",
    "for c in cat_cols: \n",
    "    indexer = StringIndexer(inputCol=c, outputCol=c+'_idx') #we pass the columns from the list as input one by one\n",
    "    combined_df = indexer.fit(combined_df).transform(combined_df) #here we fit and transform the data altogether\n",
    "    \n",
    "final_df2 = combined_df.drop(*cat_cols) #we will drop all the categorical columns we defined earlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ab_SFd3Lse5F"
   },
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "p8cL4m6vRs7q"
   },
   "outputs": [],
   "source": [
    "#drop unneed columns\n",
    "\n",
    "final_df=final_df2.drop('service','value','average','reviews_count_in_default_language','price_range', 'atmosphere','default_language','working_shifts_per_week','open_hours_per_week','open_days_per_week','popularity_generic','popularity_detailed','longitude','latitude','region','city','country','restaurant_name')\n",
    "\n",
    "cols = final_df.columns #extract the column names from the dataframe\n",
    "cols.remove('avg_rating') #remove stars -> we need this to be our label\n",
    "\n",
    "#vector assembler will take all the columns and convert them into one column called features\n",
    "assembler = VectorAssembler(inputCols=cols, outputCol='features')\n",
    "\n",
    "#the .transform will apply the changes here\n",
    "final_df = assembler.transform(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3om2mKmdOTdO",
    "outputId": "b9cead77-0b05-4755-b433-343e973c65e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[vegetarian_friendly: int, vegan_options: int, gluten_free: bigint, avg_rating: int, total_reviews_count: bigint, excellent: double, very_good: double, poor: double, terrible: double, food: double, price_range_idx: double, cuisines_idx: double, claimed_idx: double, features: vector]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we can now see that features column will appear within the dataframe\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eEXpo5yfOTdO"
   },
   "source": [
    "\n",
    "Lets Split\n",
    "\n",
    "80% in training set and 20% is testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "UAAWTr8qOTdP"
   },
   "outputs": [],
   "source": [
    "# We will now create a new dataframe only consisting of the features column and the label column (actually stars column but renamed)\n",
    "df_data = final_df.select(col('features'), col('avg_rating').alias('label'))\n",
    "\n",
    "#simple data splitting\n",
    "df_train, df_test = df_data.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTwkfOrWswkW"
   },
   "source": [
    "## Train Models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "QimDWBJhOTdP"
   },
   "outputs": [],
   "source": [
    "# Import some classifiers and multiclass evaluator\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier, LogisticRegression, GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFK296zBug7u"
   },
   "source": [
    "### 1st Classification Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "2z4OBK9SOTdQ"
   },
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\" ,maxBins=800000)\n",
    "model_dt = dt.fit(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvFI9DEtuXvw"
   },
   "source": [
    "### 2nd Classification Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "GAoyDH5-u1PZ"
   },
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=8,maxDepth=5 ,maxBins=800000)\n",
    "model_rf = rf.fit(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ke8DFgiHu_WK"
   },
   "source": [
    "### 3rd Classification Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "cicu5WyGvWGy"
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8, labelCol=\"label\", featuresCol=\"features\")\n",
    "model_lr = lr.fit(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZ1MNVthFaUc"
   },
   "source": [
    "### 4 Classification Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "KYSMcpLeRs7t"
   },
   "outputs": [],
   "source": [
    "#NaiveBayes\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "nb = NaiveBayes(smoothing=1.0, \n",
    "                modelType=\"gaussian\", \n",
    "                featuresCol='features', labelCol='label')\n",
    "model_niv = nb.fit(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xdLl8k9_wG6v"
   },
   "source": [
    "## Model Evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EUP0fJJdvmQj"
   },
   "source": [
    "### 1st Model  Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "ITE4LHiQvuIh"
   },
   "outputs": [],
   "source": [
    "#  pyspark has .transform\n",
    "pred_dt = model_dt.transform(df_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WewFtASjFaUk"
   },
   "source": [
    "## report  and matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zj_ecisd_Ctk",
    "outputId": "3157dd0b-5186-442c-8459-73a34ecf6988"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.85     59778\n",
      "           1       0.81      0.65      0.72     81848\n",
      "           2       0.76      0.86      0.81     62913\n",
      "\n",
      "    accuracy                           0.79    204539\n",
      "   macro avg       0.79      0.80      0.79    204539\n",
      "weighted avg       0.79      0.79      0.78    204539\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn \n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "y_true = pred_dt.select(['label']).collect()\n",
    "y_pred = pred_dt.select(['prediction']).collect()\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3AjaooPAkHgw",
    "outputId": "1c30a5cb-c4b6-43ca-9639-51d7bb2d1571"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[53864  5000   914]\n",
      " [12334 53164 16350]\n",
      " [ 1204  7394 54315]]\n"
     ]
    }
   ],
   "source": [
    "#matrix\n",
    "from sklearn import metrics\n",
    "matrix=metrics.confusion_matrix(y_true,y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dadYirzrzGip"
   },
   "source": [
    "### 2nd Model  Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "W_xtasIr_Ctl"
   },
   "outputs": [],
   "source": [
    "#  pyspark has .transform\n",
    "pred_rf = model_rf.transform(df_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mnwakwvlFaUl"
   },
   "source": [
    "## report  and matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XZf3SMe2_Ctl",
    "outputId": "6bdfc908-1667-4920-b780-f363163d7afd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.86     59778\n",
      "           1       0.79      0.71      0.75     81848\n",
      "           2       0.77      0.86      0.81     62913\n",
      "\n",
      "    accuracy                           0.80    204539\n",
      "   macro avg       0.80      0.81      0.81    204539\n",
      "weighted avg       0.80      0.80      0.80    204539\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_true3 = pred_rf.select(['label']).collect()\n",
    "y_pred3 = pred_rf.select(['prediction']).collect()\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_true3, y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ou5ZxNR1kOwQ",
    "outputId": "de3e3b8b-2c8b-4f37-dda5-bbbc6361c28e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[51831  7188   759]\n",
      " [ 8587 58076 15185]\n",
      " [  198  8586 54129]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "matrix=metrics.confusion_matrix(y_true3,y_pred3)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JhqUCJrNznO6"
   },
   "source": [
    "### 3rd Model  Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "nn0OzB2G_Ctl"
   },
   "outputs": [],
   "source": [
    "#  pyspark has .transform\n",
    "pred_lr = model_lr.transform(df_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JTQkkR-FaUp"
   },
   "source": [
    "## report  and matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7-fZns6Hic28",
    "outputId": "edc13827-4ed7-4a0a-8506-7b2a5b87203e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.00      0.01     59778\n",
      "           1       0.40      1.00      0.57     81848\n",
      "           2       0.00      0.00      0.00     62913\n",
      "\n",
      "    accuracy                           0.40    204539\n",
      "   macro avg       0.46      0.33      0.19    204539\n",
      "weighted avg       0.45      0.40      0.23    204539\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true4 = pred_lr.select(['label']).collect()\n",
    "y_pred4 = pred_lr.select(['prediction']).collect()\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_true4, y_pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PuZcXT_yj6ib",
    "outputId": "d64859fb-9518-4464-bb04-d630731d3bad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  162 59616     0]\n",
      " [    3 81845     0]\n",
      " [    0 62913     0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "matrix=metrics.confusion_matrix(y_true4,y_pred4)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N9xRPPwlOTdo"
   },
   "source": [
    "### 4th Model  Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OrDS6f-lFaUv"
   },
   "source": [
    "## 5th Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "K1N_NxawRs7v"
   },
   "outputs": [],
   "source": [
    "pred_nb = model_niv.transform(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U87LdQfVFaUv"
   },
   "source": [
    "## report  and matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ThDvggnDikx_",
    "outputId": "2bd365b0-1738-4f49-c3a8-7fc7be1f0fa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.96      0.56     59778\n",
      "           1       0.82      0.15      0.26     81848\n",
      "           2       0.64      0.45      0.53     62913\n",
      "\n",
      "    accuracy                           0.48    204539\n",
      "   macro avg       0.62      0.52      0.45    204539\n",
      "weighted avg       0.64      0.48      0.43    204539\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true6 = pred_nb.select(['label']).collect()\n",
    "y_pred6 = pred_nb.select(['prediction']).collect()\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_true6, y_pred6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ge1ZeMFgjvZd",
    "outputId": "53bf2638-fa58-438f-bea6-f862d1a3d898"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[57468  1547   763]\n",
      " [54253 12473 15122]\n",
      " [33656  1179 28078]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "matrix=metrics.confusion_matrix(y_true6,y_pred6)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3Qt31q9OTdp"
   },
   "source": [
    "## Show ML Evaluation as Dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "O0qIeaoFOTdp"
   },
   "outputs": [],
   "source": [
    "# Accuracy Metric\n",
    "evaluator_A = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "# F1 Metric\n",
    "evaluator_F = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "# Weighted Precision\n",
    "evaluator_P = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "\n",
    "# Weighted Recall\n",
    "evaluator_R = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "\n",
    "# Our models\n",
    "models = [pred_dt, pred_rf, pred_lr,pred_nb]\n",
    "\n",
    "# Empty lists that will store the scores for each metric for each model.\n",
    "accuracy = []\n",
    "F1 = []\n",
    "precision = []\n",
    "recall = []\n",
    "\n",
    "# Simple loop to populate the empty lists with scores of models for each metric.\n",
    "for model in models:\n",
    "    accuracy.append(evaluator_A.evaluate(model))\n",
    "    F1.append(evaluator_F.evaluate(model))\n",
    "    precision.append(evaluator_P.evaluate(model))\n",
    "    recall.append(evaluator_R.evaluate(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "lu-KfupAOTdq"
   },
   "outputs": [],
   "source": [
    "# We will convert all lists created above into a dataframe for easy viewing.\n",
    "df_ev = pd.DataFrame(list(zip(accuracy, F1, precision, recall)), \n",
    "                     columns = ['Accuracy', 'F1-Score', 'Weighted Precision', 'Weighted Recall'],\n",
    "                     index = ['Decision Tree', 'Random Forest', 'Logistic Regression','nive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "PFmrj7FnOTdq",
    "outputId": "d0394f8d-52a3-4ae6-fe6f-06a7e7358360"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-3e559cca-8086-465f-bda7-4b5a8d1ba469\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Weighted Precision</th>\n",
       "      <th>Weighted Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.788813</td>\n",
       "      <td>0.784640</td>\n",
       "      <td>0.791462</td>\n",
       "      <td>0.788813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.801979</td>\n",
       "      <td>0.800552</td>\n",
       "      <td>0.802186</td>\n",
       "      <td>0.801979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.400936</td>\n",
       "      <td>0.230430</td>\n",
       "      <td>0.447194</td>\n",
       "      <td>0.400936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nive</th>\n",
       "      <td>0.479219</td>\n",
       "      <td>0.428210</td>\n",
       "      <td>0.640365</td>\n",
       "      <td>0.479219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e559cca-8086-465f-bda7-4b5a8d1ba469')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-3e559cca-8086-465f-bda7-4b5a8d1ba469 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-3e559cca-8086-465f-bda7-4b5a8d1ba469');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                     Accuracy  F1-Score  Weighted Precision  Weighted Recall\n",
       "Decision Tree        0.788813  0.784640            0.791462         0.788813\n",
       "Random Forest        0.801979  0.800552            0.802186         0.801979\n",
       "Logistic Regression  0.400936  0.230430            0.447194         0.400936\n",
       "nive                 0.479219  0.428210            0.640365         0.479219"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceobXQ5CdiU1"
   },
   "source": [
    "the best model is random tree with 0.80 Accuracy , and the worest model is Logistic Regression\t with 0.40 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CO53Znc6d-4g"
   },
   "source": [
    "### select model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47wixViTcUOe"
   },
   "source": [
    "Random Forst is the best model with accurcy 0.80 and \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vTXVWTI6pM1Q"
   },
   "source": [
    "# ML Pipeline for Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "DvFjydhN_Ctn"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "w2LyCJz2_Cto"
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[rf])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "G_uJ78I2_Cto"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Fit the pipeline to training documents.\n",
    "model = pipeline.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nTkALjLbV3Wc",
    "outputId": "fbad4ae8-1140-4127-dbe7-fbe1007104e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8019790846733386"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets try to get the accuracy of our model on the testing set\n",
    "evaluator_A.evaluate(model.transform(df_test))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
